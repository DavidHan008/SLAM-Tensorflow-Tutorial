{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors in Tensorflow\n",
    "本節重點  \n",
    "1. 幾種用來裝 Tensor 的容器: \n",
    "  1. constant\n",
    "  2. placeholder\n",
    "  3. variable\n",
    "  4. random tensor\n",
    "\n",
    "## Constants\n",
    "常數的意義在於  \n",
    "1. 值不會更動\n",
    "2. 不會是微分的對象\n",
    "\n",
    "常見的 constants 是 `tf.zeros` 和 `tf.ones`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 1.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import slim\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.zeros([1])\n",
    "y = x + 1\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "x_num, y_num = sess.run([x, y])\n",
    "print(x_num, y_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF 其實有一個專門的 tf.constant 給你放常數。  \n",
    "你可以把 numpy array 直接餵給 tf.constant 來指定常數。(但很少用得到)  \n",
    "常數最直覺的用法就是直接寫在式子裡面。  \n",
    "例如上例中的 `y = x + 1` 其實那個 `1` 就是常數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session\n",
    "這邊另一個要說明的重點是 session。  \n",
    "Session 是讓 computational graph 動起來的平台。  \n",
    "也就是讓 symbolic variable 被賦予數值的機制。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros_2:0\", shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你發現這根本沒有給你任何有用的資訊。  \n",
    "因為，就像我前面強調的：TF的所有東西都是 symbolic variable/operation  \n",
    "你不要期待說你能靠著 print 來得到什麼。  \n",
    "乖乖的用 session 來取得數值吧!  \n",
    "\n",
    "*給對 Python 不熟的人：sess 回傳的結果是 numpy array  \n",
    "Numpy 是類似 MATLAB 的東西。主要的用途就是數值運算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "「墊檔」，這東西是個空架子。讓你給 model 預告說：這是我以後會餵 data 進來的地方。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 0.]\n",
      " [ 0.]]\n",
      "y =  [[ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "y = x + 1\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "x_num = np.zeros([2, 1])\n",
    "y_num = sess.run(y, feed_dict={x: x_num})\n",
    "print('x = ', x_num)\n",
    "print('y = ', y_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.placeholder 要求你給兩個 argument:  \n",
    "1. 資料型態：通常我們都是給 tf.float32，因為 GPU 運算是用 float 不是 double  \n",
    "2. 形狀。第一維通常是 batch size。不必給死，給 None 代表「任意形狀」\n",
    "\n",
    "\n",
    "### 餵食 (feed_dict)\n",
    "在要求 session 計算 symbolic variable 的值的時候，你必須要把真正的 input 透過 placeholder 餵進去。  \n",
    "方法是透過 `run` 的 argument `feed_dict`  \n",
    "其中，key 為 symbolic variable, value 為 numerical variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "tf.Variable 才是正格的 symbolic variable。  \n",
    "但因為我們都會使用 wrapper 的關係，tf.Variable 反而最少用到。  \n",
    "使用這東西最重要的是要在整張 computational graph 建好之後宣告 initializer  \n",
    "並且叫 session 去 run 他\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[-0.78194946]\n",
      " [-0.72481132]]\n",
      "y =  [[ 0.21805054]\n",
      " [ 0.27518868]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(\n",
    "    tf.random_normal(shape=[2, 1]),\n",
    "    name='x')\n",
    "y = x + 1\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Variable Initialization\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "x_num, y_num = sess.run([x, y])\n",
    "print('x = ', x_num)\n",
    "print('y = ', y_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Initialization\n",
    "凡是有使用到 tf.Variable 的情況，就必須要做 initialization  \n",
    "所謂的 initialization 分為兩個部分\n",
    "1. 在宣告變數的時候給的 initialization  \n",
    "   tf.Variable 的第一個 argument 就是 initial value  \n",
    "   最常見的給法 random initialization (畢竟這是 neural network)  \n",
    "   其實塞入 Numpy array 也可以。但通常不會這樣幹 (寫幾個 model 之後你就知道了)。\n",
    "2. 真正將 numerical value 裝載到 symbolic variable 中  \n",
    "   也就是  \n",
    "   ```\n",
    "   init = tf.global_variables_initializer()\n",
    "   sess.run(init)\n",
    "   ```\n",
    "\n",
    "如果你搞不清楚什麼時候要做2，\n",
    "反正當你定義完整張 graph 之後，做這個動作就對了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "這是比較奇葩的一個。通常是透過以下兩者取得\n",
    "```\n",
    "tf.random_normal\n",
    "tf.random_uniform\n",
    "```\n",
    "常見的使用時機是當作 tf.Variable 的 initializer；\n",
    "但在這個 wrapper 為王的時代，\n",
    "你幾乎不會親自遇見 tf.Variable，自然也就不會用到 tf.random_xxx 了。\n",
    "\n",
    "另一個使用時機是拿來當作 random noise generator\n",
    "這在 VAE 或 GAN 裡面會用到。\n",
    "須注意："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57358313]\n",
      " [-0.08674288]]\n"
     ]
    }
   ],
   "source": [
    "z = tf.random_uniform(\n",
    "    shape=[2, 1],\n",
    "    minval=-1.,\n",
    "    maxval=1.)\n",
    "\n",
    "z_num = sess.run(z)\n",
    "print(z_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "你會發現：每次取值的時候，他回傳的值都不一樣。\n",
    "那為什麼拿來當 tf.Variable 的 initializer 卻沒問題呢?\n",
    "因為 tf.Variable 的 initializer 只會取值一次而已 \n",
    "(你只會跑一次 tf.global_variables_initializer)\n",
    "\n",
    "另一個要提點的是：雖然 tf.random_xxx 的形狀不能有 None\n",
    "但是如果你是從其他的 Tensor 借形狀過來的話就可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = tf.random_normal(shape=[None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "這樣是不行的!\n",
    "\n",
    "但以下這樣就可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 2])\n",
    "z = tf.random_normal(shape=tf.shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
